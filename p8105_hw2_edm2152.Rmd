---
title: "p8105_hw2_edm2152"
author: "Eric Morris"
date: "September 25, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

## Problem 1

Reading and cleaning the data; retaining line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Converting the entry variable from character (YES vs NO) to a logical variable using ifelse. 

```{r Importing Transit Data}
subway_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:vending, - exit_only, vending, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

This dataset contains variables for the subway line (name), station name, longitude and latitude for station location, subway routes served by the station spread across columns, if the location is an entrance, the entrance type, whether or not there is a vending at the entrance, and if the entrance is ADA compliant. This dataset contains `{r} nrow(subway_data)` rows (observations) and `{r} ncol(subway_data)` columns (variables). This dataset is relatively tidy (?). 

There are `{r} distinct(subway_data, line, station_name) %>% nrow()` distinct stations in this dataset. 

There are `{r} distinct(subway_data, line, station_name, ada) %>% filter(ada == TRUE) %>% nrow()` ADA compliant stations among the 465 distinct stations. 

```{r}
prop_vend_entr = 
  (
  select(subway_data, entry, vending) %>% 
 filter(entry == TRUE) %>% 
  filter(vending == "NO") %>% 
  count()
/
  select(subway_data, vending) %>% 
 filter(vending == "NO") %>% 
  count()
)
```

The proportion of station entrances/exits without vending that allow entrance is `{r} prop_vend_entr` 


Reformatting the dataset so that route number and route name are distinct variables using the gather command: 

```{r Gathering Subway Data}
subway_data_reformatted = 
  gather(subway_data, key = route_number, value = route_name, route1:route11)
```


```{r A Train}
distinct_A_stations = 
  distinct(subway_data_reformatted, line, station_name, route_name) %>% 
  filter(route_name == "A") %>% 
  nrow()

distinct_A_ADA = 
  distinct(subway_data_reformatted, line, station_name, route_name, ada) %>% 
  filter(route_name == "A") %>% 
  filter(ada == TRUE) %>% 
  nrow()
```

`{r} distinct_A_stations` distinct stations serve the A train, `{r} distinct_A_ADA` of these are ADA compliant. 

## Problem 2

Importing Mr. Trash Wheel Data, cleaning variable names, filtering out rows without a dumpster value and changing sports balls to an integer: 

```{r Mr. Trash Wheel}
mrtrash_data = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N256") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

Importing the precipitation data for 2016 and 2017 and joining them 

```{r Precipitation Data}
prcp2016 = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016)

prcp2017 = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>% 
  mutate(year = 2017)

prcpdata_16_17 = full_join(prcp2016, prcp2017) %>% 
  mutate(month = month.name[month])
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

##Problem 3

Importing and tidying the BRFSS Data: 

```{r Brfss Data}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excellent_vgood = (excellent + very_good) / 100) %>% 
  rename(state = locationabbr)
```


```{r}
unique_locations = 
brfss_data %>% 
  distinct(locationdesc) %>% 
  nrow()
```

There are `{r} unique_locations` unique locations in the dataset.  

```{r}
unique_states =
  brfss_data %>% 
  distinct(state) %>% 
  nrow()
```

Every state plus Washington D.C. is represented, as there are `{r} unique_states` unique "states" in the data set. 


```{r}
brfss_data %>% 
  count(state) %>% 
  filter(n == max(n))
```

New Jersey is the most observed state with 146 observations in the data set. 

```{r}
median_excellent_2002 = 
  brfss_data %>% 
  filter(year == 2002) %>% 
  pull(excellent) %>% 
  median(na.rm = TRUE)

median_excellent_2002
```

The median "excellent" response value in 2002 is `{r} median_excellent_2002 `. 

Below is a histogram of “Excellent” response values in the year 2002.

```{r Excellent Histogram of "Excellent"}
brfss_data %>% 
  filter(year == 2002) %>% 
ggplot(aes(x = excellent)) + 
  geom_histogram()
```

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
brfss_data %>% 
  filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>% 
  ggplot(aes(x = year, y = excellent)) +
  geom_point(aes(color = locationdesc))
```

